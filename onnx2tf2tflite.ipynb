{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import onnx\n",
    "from onnx_tf.backend import prepare\n",
    "\n",
    "# Load the ONNX model\n",
    "onnx_model = onnx.load('/home/user01/data/talha/CWD/new_model.onnx') "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# Import the ONNX model to Tensorflow\n",
    "tf_rep = prepare(onnx_model)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2023-06-07 16:38:37.519985: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1956] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "tf_rep.export_graph('/home/user01/data/talha/CWD/new_model.pb')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2023-06-07 16:41:27.413393: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor '2902' with dtype float and shape [1280]\n",
      "\t [[{{node 2902}}]]\n",
      "WARNING:absl:Found untraced functions such as gen_tensor_dict while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:Assets written to: /home/user01/data/talha/CWD/new_model.pb/assets\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2023-06-07 16:41:51.730233: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'serving_default_input' with dtype float and shape [?,3,224,224]\n",
      "\t [[{{node serving_default_input}}]]\n",
      "INFO:tensorflow:Assets written to: /home/user01/data/talha/CWD/new_model.pb/assets\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import json, requests\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load the model\n",
    "loaded_model = tf.saved_model.load('/home/user01/data/talha/CWD/new_model.pb')\n",
    "# Predict\n",
    "# Here 'serving_default' is the name of the serving signature and 'input' is the name of the input tensor. \n",
    "# These names might be different for your model. You can print out `loaded_model.signatures` to see the names in your model.\n",
    "print(loaded_model.signatures)\n",
    "# laod labesl\n",
    "imagenet_labels_url = 'https://raw.githubusercontent.com/anishathalye/imagenet-simple-labels/master/imagenet-simple-labels.json'\n",
    "labels = json.loads(requests.get(imagenet_labels_url).text)\n",
    "\n",
    "img = cv2.imread('/home/user01/data/talha/CWD/s.jpg')\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "img = cv2.resize(img, (224,224))\n",
    "img = img /255\n",
    "\n",
    "img = img[np.newaxis, ...]\n",
    "img = img.transpose(0,3,1,2)\n",
    "img = tf.convert_to_tensor(img)\n",
    "img = tf.cast(img, tf.float32)\n",
    "print(img.shape)\n",
    "\n",
    "predictions = loaded_model.signatures['serving_default'](input=img)\n",
    "preds = predictions['output']\n",
    "preds = preds.numpy()\n",
    "predicted_index = np.argmax(preds, axis=-1)[0]\n",
    "\n",
    "# Map the predicted class index to its corresponding label\n",
    "predicted_class = labels[predicted_index]\n",
    "\n",
    "print(predicted_class)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "_SignatureMap({'serving_default': <ConcreteFunction signature_wrapper(*, input) at 0x7F4DD82CC1F0>})\n",
      "(1, 3, 224, 224)\n",
      "strawberry\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "# Convert the model to TensorFlow Lite\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model('/home/user01/data/talha/CWD/new_model.pb')\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the TensorFlow Lite model\n",
    "with open(\"/home/user01/data/talha/CWD/model.tflite\", \"wb\") as f:\n",
    "    f.write(tflite_model)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2023-06-07 17:34:20.900627: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'serving_default_input' with dtype float and shape [?,3,224,224]\n",
      "\t [[{{node serving_default_input}}]]\n",
      "2023-06-07 17:34:20.931766: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
      "2023-06-07 17:34:20.931790: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
      "2023-06-07 17:34:20.931938: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /home/user01/data/talha/CWD/new_model.pb\n",
      "2023-06-07 17:34:20.936904: I tensorflow/cc/saved_model/reader.cc:89] Reading meta graph with tags { serve }\n",
      "2023-06-07 17:34:20.936925: I tensorflow/cc/saved_model/reader.cc:130] Reading SavedModel debug info (if present) from: /home/user01/data/talha/CWD/new_model.pb\n",
      "2023-06-07 17:34:20.949587: I tensorflow/cc/saved_model/loader.cc:231] Restoring SavedModel bundle.\n",
      "2023-06-07 17:34:20.996021: I tensorflow/cc/saved_model/loader.cc:215] Running initialization op on SavedModel bundle at path: /home/user01/data/talha/CWD/new_model.pb\n",
      "2023-06-07 17:34:21.029873: I tensorflow/cc/saved_model/loader.cc:314] SavedModel load for tags { serve }; Status: success: OK. Took 97934 microseconds.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "source": [
    "import numpy as np\n",
    "from pprint import pprint\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load TFLite model and allocate tensors\n",
    "interpreter = tf.lite.Interpreter(model_path=\"/home/user01/data/talha/CWD/model.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output tensors information\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "pprint(input_details)\n",
    "pprint(output_details)\n",
    "\n",
    "# Prepare your input data corresponding to the input tensor shape.\n",
    "img = cv2.imread('/home/user01/data/talha/CWD/c.jpg')\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "img = cv2.resize(img, (224,224))\n",
    "img = img /255\n",
    "\n",
    "img = img[np.newaxis, ...]\n",
    "img = img.transpose(0,3,1,2)\n",
    "img = tf.convert_to_tensor(img)\n",
    "img = tf.cast(img, tf.float32)\n",
    "input_data = img\n",
    "\n",
    "# Set the tensor to point to your input data\n",
    "interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "\n",
    "# Run the model\n",
    "interpreter.invoke()\n",
    "\n",
    "# Retrieve the output of the model\n",
    "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "\n",
    "predicted_index = np.argmax(output_data, axis=-1)[0]\n",
    "\n",
    "# Map the predicted class index to its corresponding label\n",
    "predicted_class = labels[predicted_index]\n",
    "\n",
    "print(predicted_class)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[{'dtype': <class 'numpy.float32'>,\n",
      "  'index': 0,\n",
      "  'name': 'serving_default_input:0',\n",
      "  'quantization': (0.0, 0),\n",
      "  'quantization_parameters': {'quantized_dimension': 0,\n",
      "                              'scales': array([], dtype=float32),\n",
      "                              'zero_points': array([], dtype=int32)},\n",
      "  'shape': array([  1,   3, 224, 224], dtype=int32),\n",
      "  'shape_signature': array([ -1,   3, 224, 224], dtype=int32),\n",
      "  'sparsity_parameters': {}}]\n",
      "[{'dtype': <class 'numpy.float32'>,\n",
      "  'index': 275,\n",
      "  'name': 'PartitionedCall:0',\n",
      "  'quantization': (0.0, 0),\n",
      "  'quantization_parameters': {'quantized_dimension': 0,\n",
      "                              'scales': array([], dtype=float32),\n",
      "                              'zero_points': array([], dtype=int32)},\n",
      "  'shape': array([   1, 1000], dtype=int32),\n",
      "  'shape_signature': array([  -1, 1000], dtype=int32),\n",
      "  'sparsity_parameters': {}}]\n",
      "Egyptian Mau\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "source": [
    "tf.__version__"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'2.12.0'"
      ]
     },
     "metadata": {},
     "execution_count": 68
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "source": [
    "onnx.__version__"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'1.14.0'"
      ]
     },
     "metadata": {},
     "execution_count": 69
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "source": [
    "import onnx_tf"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "source": [
    "onnx_tf.__version__"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'1.10.0'"
      ]
     },
     "metadata": {},
     "execution_count": 72
    }
   ],
   "metadata": {}
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 4
 }
}